{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bulgarian-supplement",
   "metadata": {},
   "source": [
    "## imports and essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "occupational-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime,date\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-customs",
   "metadata": {},
   "source": [
    "## Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "healthy-mixer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-25 19:20:40\n",
      "1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t\n",
      "2021-03-25 19:21:27\n"
     ]
    }
   ],
   "source": [
    "sn=1\n",
    "#We use 'c' as both the serial number and the time count for bypassing anti-crawler\n",
    "datentime=str(date.today())\n",
    "datentime+=\" \"\n",
    "datentime+=datetime.now().strftime(\"%H:%M:%S\")\n",
    "print(datentime)\n",
    "with open('csv_files/articles.csv','w',encoding=\"utf-8\")as outfile, open(\"text_files/article_links.txt\",\"r\",encoding='utf-8') as infile:\n",
    "    writer=csv.writer(outfile)\n",
    "    writer.writerow([\"SN\",\"Title\", \"Content\"])\n",
    "    for line in infile:\n",
    "        print(\"%d \\t\"%sn,end='')\n",
    "        if(sn%10==0):time.sleep(61)\n",
    "        page = requests.get(line,headers=headers)\n",
    "        soup = BeautifulSoup(page.content, 'lxml')\n",
    "        title=soup.find(class_=\"blog_entry-title\")\n",
    "        y=str(soup.find(class_=\"entry-content\"))\n",
    "        content=y.replace('\\n','').replace('\\r\\n','').replace('\\r','')\n",
    "        writer.writerow([sn,title,content])\n",
    "        sn+=1\n",
    "        if(sn==10):break\n",
    "            \n",
    "datentime=str(date.today())\n",
    "datentime+=\" \"\n",
    "datentime+=datetime.now().strftime(\"%H:%M:%S\")\n",
    "print(\"\\n\"+datentime)\n",
    "\n",
    "# There are newline characters in the articles that were fetched. This causes unorganized csv structure.\n",
    "# We have to find a new for writerow to work without considering newline characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-arrangement",
   "metadata": {},
   "source": [
    "### Attempting to parse into txt file (Successful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "partial-cleanup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-25 19:28:57\n",
      "1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t\n",
      "2021-03-25 19:29:28\n"
     ]
    }
   ],
   "source": [
    "sn=1\n",
    "#We use 'c' as both the serial number and the time count for bypassing anti-crawler\n",
    "datentime=str(date.today())\n",
    "datentime+=\" \"\n",
    "datentime+=datetime.now().strftime(\"%H:%M:%S\")\n",
    "print(datentime)\n",
    "with open('text_files/articles.txt','w',encoding=\"utf-8\")as outfile, open(\"text_files/article_links.txt\",\"r\",encoding='utf-8') as infile:\n",
    "    outfile.write(\"This is a test\\n\")\n",
    "    for line in infile:\n",
    "        print(\"%d \\t\"%sn,end='')\n",
    "        if(sn%10==0):time.sleep(61)\n",
    "        page = requests.get(line,headers=headers)\n",
    "        soup = BeautifulSoup(page.content, 'lxml')\n",
    "        title=soup.find(class_=\"blog_entry-title\")\n",
    "        y=str(soup.find(class_=\"entry-content\"))\n",
    "        content=y.replace('\\n','').replace('\\r\\n','').replace('\\r','')\n",
    "        outfile.write(\"%d\\t%s\\n%s\\n\"%(sn,title,content))\n",
    "        sn+=1\n",
    "        if(sn==10):break\n",
    "            \n",
    "datentime=str(date.today())\n",
    "datentime+=\" \"\n",
    "datentime+=datetime.now().strftime(\"%H:%M:%S\")\n",
    "print(\"\\n\"+datentime)\n",
    "\n",
    "# There are newline characters in the articles that were fetched. This causes unorganized csv structure.\n",
    "# We have to find a new for writerow to work without considering newline characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-diagram",
   "metadata": {},
   "source": [
    "## Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.lawyersnjurists.com/doclit/deed-agreement-dissolution-partnership/\",headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'lxml')\n",
    "# print(BeautifulSoup(soup.body,\"html.parser\").prettify())\n",
    "x=soup.find(class_=\"blog_entry-title\")\n",
    "y=soup.find(class_=\"entry-content\")\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('csv_files/articles.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"SN\",\"Title\", \"Content\"])\n",
    "    writer.writerow([1, x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=1\n",
    "s=\"Test\"\n",
    "with open('csv_files/list.csv','w')as out, open(\"text_files/test.txt\",\"r\") as f:\n",
    "    writer=csv.writer(out)\n",
    "    writer.writerow([\"SN\",\"Title\", \"Content\"])\n",
    "    for line in f:\n",
    "        writer.writerow([c,s,line.splitlines()])\n",
    "        c+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
