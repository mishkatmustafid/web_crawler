{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time, csv, webbrowser, queue, random, re, os\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime,date\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36'}\n",
    "invalid=['<','>','*','\\\\','/',':','?','\\\"','|']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-convention",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sn=1\n",
    "#We use 'c' as both the serial number and the time count for bypassing anti-crawler\n",
    "# datentime=str(date.today())\n",
    "# datentime+=\" \"\n",
    "datentime=datetime.now().strftime(\"%H:%M:%S\")\n",
    "print(\"Started at \"+datentime)\n",
    "with open('lawyer_ci/Appellate Devision/files.txt','a',encoding=\"utf-8\")as outfile, open(\"lawyer_ci\\Appellate Devision/links.txt\",\"r\",encoding='utf-8') as infile:\n",
    "#     outfile.write(\"This is a test\\n\")\n",
    "    for line in infile:\n",
    "        if(sn<1):\n",
    "            sn+=1\n",
    "            continue\n",
    "        url=\"\"\n",
    "        for i in line:\n",
    "            if(i!='\\n'):\n",
    "                url+=i\n",
    "        print(\"%d \\t\"%sn,end='')\n",
    "        page = requests.get(url,headers=headers)\n",
    "        soup = BeautifulSoup(page.content, 'lxml')\n",
    "        title=soup.find(class_=\"blog_entry-title\")\n",
    "        y=str(soup.find(class_=\"entry-content\"))\n",
    "        it=1\n",
    "        while('None' in y):\n",
    "            if(it>5):break\n",
    "            page = requests.get(url,headers=headers)\n",
    "            soup = BeautifulSoup(page.content, 'lxml')\n",
    "            title=soup.find(class_=\"blog_entry-title\")\n",
    "            y=str(soup.find(class_=\"entry-content\"))\n",
    "            it+=1\n",
    "        content=y.replace('\\n','').replace('\\r\\n','').replace('\\r','')\n",
    "        outfile.write(\"%d\\t%s\\n%s\\n\"%(sn,title,content))\n",
    "        sn+=1\n",
    "        if(sn%10==1):\n",
    "#             datentime=str(date.today())\n",
    "#             datentime+=\" \"\n",
    "            datentime=datetime.now().strftime(\"%H:%M:%S\")\n",
    "            print(\"\\n\"+datentime+\"\\n----------------------------------------------------------------\")\n",
    "        # if(sn>=1500):break\n",
    "#         if(sn>1500):break\n",
    "# datentime=str(date.today())\n",
    "# datentime+=\" \"\n",
    "datentime=datetime.now().strftime(\"%H:%M:%S\")\n",
    "print(\"\\nDone at \"+datentime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://www.lawyersnjurists.com/doclit/affidavit-5/\nhttps://www.lawyersnjurists.com/doclit/affidavit-4/\nhttps://www.lawyersnjurists.com/doclit/supplementary-affidavit-on-behalf-of-the-petitioner-2/\nhttps://www.lawyersnjurists.com/doclit/affidavit-of-compliance-13/\nhttps://www.lawyersnjurists.com/doclit/affidavit-of-compliance-10/\nhttps://www.lawyersnjurists.com/doclit/to-sell-shares/\nhttps://www.lawyersnjurists.com/doclit/affidavit-of-compliance-9/\nhttps://www.lawyersnjurists.com/doclit/affidavit-of-compliance-8/\nhttps://www.lawyersnjurists.com/doclit/affidavit-of-compliance-7/\nhttps://www.lawyersnjurists.com/doclit/affidavit-of-compliance-5/\nhttps://www.lawyersnjurists.com/doclit/affidavit-of-compliance-4/\nhttps://www.lawyersnjurists.com/doclit/affidavit-of-compliance-3/\nhttps://www.lawyersnjurists.com/doclit/affidavit-of-compliance-2/\n"
     ]
    }
   ],
   "source": [
    "urls=[]\n",
    "with open('lawyer_ci/Documentation/Affidavit.html','r',encoding='utf-8')as file:\n",
    "    for line in file:\n",
    "        urls=line.split(',')\n",
    "for i in urls:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# urls.append(url)\n",
    "while(urls!=[]):\n",
    "    url=urls.pop(0)\n",
    "    page = requests.get(url,headers=headers)\n",
    "    if(page.status_code!=200):\n",
    "        urls.append(url)\n",
    "        print(\"%d %d\"%(page.status_code, len(urls)))\n",
    "        continue\n",
    "    soup = BeautifulSoup(page.content, 'lxml')\n",
    "    line=str(soup.find(class_=\"jtv-title\"))\n",
    "    # i=line.find('>')+1\n",
    "    i=line.find('<h2>')+4\n",
    "    j=line.find('</h2>')\n",
    "    title=line[i:j].strip()\n",
    "    for i in invalid:\n",
    "        title=title.replace(i,'')\n",
    "    title=title[:200]\n",
    "    # content=str(soup.find(class_=\"entry-content\"))\n",
    "    content=str(soup)\n",
    "    # if(os.path.isfile('lawyer_ci/Documentation/'+title+'.html')==False):\n",
    "    with open('lawyer_ci/Documentation/Affidavit/'+title+'.html','a',encoding='utf-8') as outfile:\n",
    "        # outfile.write(\"%s\\n%s\"%(line,content))\n",
    "        outfile.write(content)\n",
    "    print(\"%d %d\"%(page.status_code, len(urls)))\n",
    "    # if(len(urls)%100==0):\n",
    "    #     with open('checkpoint_scraper.txt','w',encoding='utf-8')as f:\n",
    "    #         for i in urls:\n",
    "    #             f.write(\"\\\"%s\\\",\\n\"%i)\n",
    "    #             print(\"Checkpoint\")\n",
    "    # if(sn>=1500):break\n",
    "#         if(sn>1500):break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lawyer_ci/Documentation/Acknowledgement Letter.html\nlawyer_ci/Documentation/Affidavit.html\nlawyer_ci/Documentation/Agreement Vetting.html\nlawyer_ci/Documentation/Bank Guarantee.html\nlawyer_ci/Documentation/Board Resolutions of Company.html\nlawyer_ci/Documentation/Corporate Guarantee.html\nlawyer_ci/Documentation/Deed of agreement.html\nlawyer_ci/Documentation/Deed of Assignment.html\nlawyer_ci/Documentation/Deed of Cancellation.html\nlawyer_ci/Documentation/Deed of floating charge.html\nlawyer_ci/Documentation/Deed of further charge.html\nlawyer_ci/Documentation/Deed of Negetive Pledge.html\nlawyer_ci/Documentation/Deed of Redemption &amp; Revocation.html\nlawyer_ci/Documentation/Deed-of-Partition.html\nlawyer_ci/Documentation/Dissolution.html\nlawyer_ci/Documentation/Facility agreement and Paripasu.html\nlawyer_ci/Documentation/Formation &amp; related Documents of a Company.html\nlawyer_ci/Documentation/Forwarding.html\nlawyer_ci/Documentation/Heba Deed-Bangla.html\nlawyer_ci/Documentation/Hire Purchase.html\nlawyer_ci/Documentation/Hypothecation.html\nlawyer_ci/Documentation/IGPA to Sell Hypo.html\nlawyer_ci/Documentation/IGPA to Sell Land.html\nlawyer_ci/Documentation/Letter of Authority.html\nlawyer_ci/Documentation/Letter of Continuity.html\nlawyer_ci/Documentation/Letter of Guarantee.html\nlawyer_ci/Documentation/Letter of indemnity.html\nlawyer_ci/Documentation/Letter of Lien.html\nlawyer_ci/Documentation/Letter of Satisfaction.html\nlawyer_ci/Documentation/Memo of Understanding.html\nlawyer_ci/Documentation/Memorandum Deposite of Title Deed.html\nlawyer_ci/Documentation/Mortgage Deed.html\nlawyer_ci/Documentation/Notice.html\nlawyer_ci/Documentation/Others.html\nlawyer_ci/Documentation/Paripassu Security.html\nlawyer_ci/Documentation/Personal Guarantee.html\nlawyer_ci/Documentation/Power of Attorney.html\nlawyer_ci/Documentation/Property Vetting.html\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "locs = (glob.glob('lawyer_ci/Documentation/*.html'))\n",
    "for x in range(len(locs)):\n",
    "    locs[x]=locs[x].replace('\\\\','/')\n",
    "for loc in locs:\n",
    "    print(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "with open('lawyer_ci/Documentation/Affidavit.html','r',encoding='utf-8')as file:\n",
    "    for line in file:\n",
    "        urls=line.split(',')\n",
    "# urls.append(url)\n",
    "while(urls!=[]):\n",
    "    url=urls.pop(0)\n",
    "    page = requests.get(url,headers=headers)\n",
    "    if(page.status_code!=200):\n",
    "        urls.append(url)\n",
    "        print(\"%d %d\"%(page.status_code, len(urls)))\n",
    "        continue\n",
    "    soup = BeautifulSoup(page.content, 'lxml')\n",
    "    line=str(soup.find(class_=\"blog_entry-title\"))\n",
    "    i=line.find('>')+1\n",
    "    # i=line.find('<h2>')+4\n",
    "    j=line.find('</h2>')\n",
    "    title=line[i:j].strip()\n",
    "    for i in invalid:\n",
    "        title=title.replace(i,'')\n",
    "    title=title[:200]\n",
    "    # content=str(soup.find(class_=\"entry-content\"))\n",
    "    content=str(soup)\n",
    "    # if(os.path.isfile('lawyer_ci/Documentation/'+title+'.html')==False):\n",
    "    with open('lawyer_ci/Documentation/Affidavit/'+title+'.html','a',encoding='utf-8') as outfile:\n",
    "        # outfile.write(\"%s\\n%s\"%(line,content))\n",
    "        outfile.write(content)\n",
    "    print(\"%d %d\"%(page.status_code, len(urls)))\n",
    "    # if(len(urls)%100==0):\n",
    "    #     with open('checkpoint_scraper.txt','w',encoding='utf-8')as f:\n",
    "    #         for i in urls:\n",
    "    #             f.write(\"\\\"%s\\\",\\n\"%i)\n",
    "    #             print(\"Checkpoint\")\n",
    "    # if(sn>=1500):break\n",
    "#         if(sn>1500):break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}